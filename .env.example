# AstraForge IDE Environment Configuration
# Copy this file to .env and fill in your API keys

# OpenAI Configuration
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_MODEL=gpt-4
OPENAI_ORG_ID=org-your-organization-id-here
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_MODEL=gpt-4
OPENAI_ORG_ID=org-your-organization-id-here
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_MODEL=gpt-4
OPENAI_ORG_ID=org-your-organization-id-here
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_MODEL=gpt-4
OPENAI_ORG_ID=org-your-organization-id-here
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_MODEL=gpt-4
OPENAI_ORG_ID=org-your-organization-id-here

# Anthropic Configuration  
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here
ANTHROPIC_MODEL=claude-3-sonnet-20240229
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here
ANTHROPIC_MODEL=claude-3-sonnet-20240229
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here
ANTHROPIC_MODEL=claude-3-sonnet-20240229
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here
ANTHROPIC_MODEL=claude-3-sonnet-20240229
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here
ANTHROPIC_MODEL=claude-3-sonnet-20240229

# xAI (Grok) Configuration
XAI_API_KEY=xai-your-xai-api-key-here
XAI_MODEL=grok-beta
XAI_API_KEY=xai-your-xai-api-key-here
XAI_MODEL=grok-beta
XAI_API_KEY=xai-your-xai-api-key-here
XAI_MODEL=grok-beta
XAI_API_KEY=xai-your-xai-api-key-here
XAI_MODEL=grok-beta
XAI_API_KEY=xai-your-xai-api-key-here
XAI_MODEL=grok-beta

# OpenRouter Configuration
OPENROUTER_API_KEY=sk-or-your-openrouter-api-key-here
OPENROUTER_MODEL=openai/gpt-4
OPENROUTER_API_KEY=sk-or-your-openrouter-api-key-here
OPENROUTER_MODEL=openai/gpt-4
OPENROUTER_API_KEY=sk-or-your-openrouter-api-key-here
OPENROUTER_MODEL=openai/gpt-4
OPENROUTER_API_KEY=sk-or-your-openrouter-api-key-here
OPENROUTER_MODEL=openai/gpt-4
OPENROUTER_API_KEY=sk-or-your-openrouter-api-key-here
OPENROUTER_MODEL=openai/gpt-4

# Ollama Endpoint Configuration
OLLAMA_ENDPOINT=http://127.0.0.1:11434
OLLAMA_DEFAULT_MODEL=llama3

# LM-Studio Base URL Configuration
LM-STUDIO_BASE_URL= {$insert local port here}

# Vector Database Configuration
VECTOR_DB_PATH=./data/vectors
EMBEDDING_MODEL=text-embedding-ada-002

# Postgres Configuration (for long-term memory)
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=astraforge
POSTGRES_USER=your-username
POSTGRES_PASSWORD=your-password

# LanceDB Configuration (for short-term session memory)
LANCEDB_PATH=./data/lance

# Performance Settings
MAX_CONCURRENT_REQUESTS=3
REQUEST_TIMEOUT=30000
CACHE_TTL=3600
ENABLE_REQUEST_CACHING=true

# Development Settings
NODE_ENV=development
LOG_LEVEL=info
DEBUG_MODE=false

# GitHub Integration (optional)
GITHUB_TOKEN=ghp_your-github-token-here

# Collaboration Server (optional)
COLLABORATION_PORT=3001
ENABLE_COLLABORATION=true